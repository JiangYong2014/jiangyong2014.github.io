[{"authors":["admin"],"categories":null,"content":"Hi! I currently work at Alibaba DAMO Academy. I received my Ph.D from the joint program of ShanghaiTech University and University of Chinese Academy of Sciences. I was very fortunate to be advised by Prof. Kewei Tu. I am interested in machine learning and natural language processing.\nMy current research mainly focuses on entity understanding tasks, information retrieval (query/doc understanding), language model pretraining, multilingual NLP, structured prediction and so on. Furthermore, I also ship these cutting-edge technologies to real products and platforms.\nIn my PhD time, I mainly worked on learning latent variable models for NLP problems and ML problems.\nSpotlight of our recent work:\n Incorporating various kinds of knowledge to improve named entity recognition: embedding combination, ACE, retrieval guided learning, sparse retrieval, multi-modal NER. Knowledge distillation for learning multilingual models: structure-level KD, structural KD. Improving sequence labeling methods: designing powerful potential functions, speeding up CRF training \u0026amp; inference. Leveraging source models to improve cross-lingual ability: risk minimization, multi-view learning, word reordering. Unsupervised grammar induction: the first neural-based unsupervised parser, discriminative autoencoder, 2nd order parsing, EACL tutorial and empirical study. Multi-view learning for NER, entity linking and cross-lingual learning. Fun with KL divergence: KL(p(*|a, b, c) || p(*|d, e)), KL(P || p), KL(p || q), KL(tractable || intractable?), KL (different modality).  We have some research intern positions available in Alibaba DAMO Academy. If you are interested in NLP and ML, please feel free to contact me: jiangyong.ml@gmail.com.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jiangyong.site/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hi! I currently work at Alibaba DAMO Academy. I received my Ph.D from the joint program of ShanghaiTech University and University of Chinese Academy of Sciences. I was very fortunate to be advised by Prof. Kewei Tu. I am interested in machine learning and natural language processing.\nMy current research mainly focuses on entity understanding tasks, information retrieval (query/doc understanding), language model pretraining, multilingual NLP, structured prediction and so on. Furthermore, I also ship these cutting-edge technologies to real products and platforms.","tags":null,"title":"Yong Jiang","type":"authors"},{"authors":["Chengyue Jiang**","Yong Jiang","Weiqi Wu","Pengjun Xie","Kewei Tu"],"categories":["Entity Typing","NER","Graphical Model"],"content":"","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664582400,"objectID":"d81940c6d201d45078c484c7d22258d5","permalink":"https://jiangyong.site/publication/jiang-2022-npcrf/","publishdate":"2022-10-01T00:00:00Z","relpermalink":"/publication/jiang-2022-npcrf/","section":"publication","summary":"A SOTA system that can perform entity typing tasks of 10k entity types.","tags":null,"title":"Modeling Label Correlations for Ultra-Fine Entity Typing with Neural Pairwise Conditional Random Field","type":"publication"},{"authors":["Xinyu Wang**","Yongliang Shen","Jiong Cai","Tao Wang","Xiaobin Wang","Pengjun Xie","Fei Huang","Weiming Lu","Yueting Zhuang","Kewei Tu","Wei Lu","Yong Jiang"],"categories":["Sequence Labeling","NER","Multi-lingual NLP"],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"436418a39fe30fa8dc89dbc85b699fa8","permalink":"https://jiangyong.site/publication/wang-etal-2022-semeval/","publishdate":"2022-06-01T00:00:00Z","relpermalink":"/publication/wang-etal-2022-semeval/","section":"publication","summary":"We utilize the wikipedia to improve the RaNER model, which wins the SemEval 2022 competition and obtains the **best system paper award**.","tags":null,"title":"DAMO-NLP at SemEval-2022 Task 11: A Knowledge-based System for Multilingual Named Entity Recognition","type":"publication"},{"authors":["Xinyin Ma**","Yong Jiang","Nguyen Bach","Tao Wang","Fei Huang","Weiming Lu"],"categories":["Entity Linking"],"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"edea1eaec85d9d0ef98979105eb42148","permalink":"https://jiangyong.site/publication/ma-etal-2021-muver/","publishdate":"2020-09-16T05:36:09.497101Z","relpermalink":"/publication/ma-etal-2021-muver/","section":"publication","summary":"Our first work on entity linking. Stay tuned for follow-up works.","tags":null,"title":"MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations","type":"publication"},{"authors":["Xinyu Wang**","Yong Jiang","Nguyen Bach","Tao Wang","Fei Huang","Kewei Tu"],"categories":["Sequence Labeling","Structured Prediction","NER","Multi-lingual NLP"],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"04244821d3c6c41450068e73bd7e2bec","permalink":"https://jiangyong.site/publication/wang-etal-2021-ace/","publishdate":"2020-09-16T05:36:09.497101Z","relpermalink":"/publication/wang-etal-2021-ace/","section":"publication","summary":"This paper achieves SOTA performance over 24 datasets of 6 tasks, spanning over NER, POS, chunking, dependency parsing, semantic parsing, aspect extraction, following the **More Embeddings, Better Sequence Labelers** paper.","tags":null,"title":"Automated Concatenation of Embeddings for Structured Prediction","type":"publication"},{"authors":["Xinyu Wang**","Yong Jiang","Nguyen Bach","Tao Wang","Fei Huang","Kewei Tu"],"categories":["Sequence Labeling","NER"],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"6a2e3e884e35ca9d5a101091f4278d0a","permalink":"https://jiangyong.site/publication/wang-etal-2021-retrieval/","publishdate":"2020-09-16T05:36:09.497101Z","relpermalink":"/publication/wang-etal-2021-retrieval/","section":"publication","summary":"The first retrieval-aug NER (RaNER) system that achieves SOTA performance over multiple domains.","tags":null,"title":"Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning","type":"publication"},{"authors":["Zechuan Hu**","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":["Sequence Labeling","NER","Multi-lingual NLP"],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"5328ed7c0ae83bf1761451b03cbaa2b1","permalink":"https://jiangyong.site/publication/hu-2021-multiview/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/publication/hu-2021-multiview/","section":"publication","summary":"One of my favorite work on the cross-lingual structured prediction task. The idea is super intuitive.","tags":null,"title":"Multi-View Cross-Lingual Structured Prediction with Minimum Supervision","type":"publication"},{"authors":["Songlin Yang**","Yong Jiang","Wenjuan Han","Kewei Tu"],"categories":["Parsing","Grammar Induction"],"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"ad30276f66f6afabb175e3d2e488b5d3","permalink":"https://jiangyong.site/publication/yang-2020-2nd-udp/","publishdate":"2020-09-16T05:36:09.490669Z","relpermalink":"/publication/yang-2020-2nd-udp/","section":"publication","summary":"The current SOTA model for unsupervised dependency parsing.","tags":null,"title":"Second Order Unsupervised Neural Dependency Parsing","type":"publication"},{"authors":["Xinyu Wang**","Yong Jiang","Nguyen Bach","Tao Wang","Fei Huang","Kewei Tu"],"categories":["Sequence Labeling","Multi-lingual NLP"],"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"2eb030740d56f3525a033cde3bfd65cf","permalink":"https://jiangyong.site/publication/wang-etal-2020-structure/","publishdate":"2020-09-16T05:36:09.497101Z","relpermalink":"/publication/wang-etal-2020-structure/","section":"publication","summary":"One model for multiple languages.","tags":null,"title":"Structure-Level Knowledge Distillation For Multilingual Sequence Labeling","type":"publication"},{"authors":["Jiong Cai**","Yong Jiang","Kewei Tu"],"categories":["Grammar Induction","Parsing","Latent Variable Model"],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"34dbdbb940bdc8ec3bd482e4e89ddae7","permalink":"https://jiangyong.site/publication/cai-2017-crf/","publishdate":"2020-09-16T05:36:09.48619Z","relpermalink":"/publication/cai-2017-crf/","section":"publication","summary":"The first autoencoder model to unsupervised dependency parsing.","tags":null,"title":"CRF Autoencoder for Unsupervised Dependency Parsing","type":"publication"},{"authors":["Jiang Yong","Wenjuan Han","Kewei Tu"],"categories":["Grammar Induction","Parsing","Latent Variable Model"],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"ee1b3d464158c932ec1bf677322178f6","permalink":"https://jiangyong.site/publication/yong-2016-unsupervised/","publishdate":"2020-09-16T05:36:09.484104Z","relpermalink":"/publication/yong-2016-unsupervised/","section":"publication","summary":"The first neural approach to unsupervised dependency parsing.","tags":null,"title":"Unsupervised Neural Dependency Parsing","type":"publication"}]