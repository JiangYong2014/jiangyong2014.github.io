---
# Display name
name: Yong Jiang

# Username (this should match the folder name)
authors:
- admin

# Is this the primary user of the site?
superuser: true

# Role/position
role: 

# Organizations/Affiliations
organizations:
- name: Alibaba DAMO Academy
  url: ""

# Short bio (displayed in user profile at end of posts)
bio: My research interests include natural language processing and machine learning.

interests:
- Natural Language Processing  
- Machine Learning
- Deep Learning

education:
  courses:
  - course: PhD in Computer Science
    institution: ShanghaiTech University
    year: 2019
  - course: PhD in Computer Science
    institution: University of Chinese Academy of Sciences
    year: 2019


# Social/Academic Networking
# For available icons, see: https://sourcethemes.com/academic/docs/widgets/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:jiangyong.ml@gmail.com" or "#contact" for contact widget.
social:
- icon: envelope
  icon_pack: fas
  link: '#contact'  # For a direct email link, use "mailto:jiangyong.ml@gmail.com".
- icon: weibo
  icon_pack: fab
  link: http://weibo.com/u/1845215855
- icon: google-scholar
  icon_pack: ai
  link: https://scholar.google.com/citations?user=sxXZWQQAAAAJ&hl=en
- icon: linkedin
  icon_pack: fab
  link: https://www.linkedin.com/in/yong-jiang-652625120/
# Link to a PDF of your resume/CV from the About widget.
# To enable, copy your resume/CV to `static/files/cv.pdf` and uncomment the lines below.  
# - icon: cv
#   icon_pack: ai
#   link: files/cv.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: "jiangyong.ml@gmail.com"
  
# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.  
user_groups:
- Researchers
- Visitors
---

Hi! I currently work at [Alibaba DAMO Academy](https://damo.alibaba.com/). I received my Ph.D from the joint program of ShanghaiTech University and University of Chinese Academy of Sciences. I was very fortunate to be advised by [Prof. Kewei Tu](http://faculty.sist.shanghaitech.edu.cn/faculty/tukw/). I am interested in machine learning and natural language processing. 

My current research mainly focuses on entity understanding tasks, information retrieval (query/doc understanding), language model pretraining, multilingual NLP, structured prediction and so on. Furthermore, I also ship these cutting-edge technologies to real products and platforms. 

In my PhD time, I mainly worked on learning latent variable models for NLP problems and ML problems.

Spotlight of our recent work:

1. Incorporating various kinds of knowledge to improve named entity recognition: [embedding combination](https://arxiv.org/abs/2009.08330), [ACE](https://arxiv.org/abs/2010.05006), [retrieval guided learning](https://arxiv.org/abs/2105.03654), [sparse retrieval](https://arxiv.org/abs/2203.00545), [multi-modal NER](https://arxiv.org/abs/2112.06482).
2. Knowledge distillation for learning multilingual models: [structure-level KD](https://arxiv.org/abs/2004.03846), [structural KD](https://arxiv.org/abs/2010.05010).
3. Improving sequence labeling methods: [designing powerful potential functions](https://arxiv.org/abs/2011.05604), [speeding up CRF training & inference](https://openreview.net/pdf?id=ZrBZrf-BS3Z).
4. Leveraging source models to improve cross-lingual ability: [risk minimization](https://aclanthology.org/2021.acl-long.380/), [multi-view learning](https://aclanthology.org/2021.acl-long.207/), [word reordering](https://aclanthology.org/2021.emnlp-main.338/).
5. Unsupervised grammar induction: [the first neural-based unsupervised parser](https://aclanthology.org/D16-1073/), [discriminative autoencoder](https://arxiv.org/abs/1708.01018), [2nd order parsing](https://arxiv.org/abs/2010.14720), [EACL tutorial](https://github.com/tukw/unsupervised-parsing-tutorial) and [empirical study](https://www.aclweb.org/anthology/2020.acl-main.300/).
6. Multi-view learning for [NER](https://arxiv.org/abs/2105.03654), [entity linking](https://arxiv.org/abs/2109.05716) and [cross-lingual learning](https://aclanthology.org/2021.acl-long.207/).
7. Fun with KL divergence: [KL(p(\*|a, b, c) || p(\*|d, e))](https://aclanthology.org/2021.acl-long.207/), [KL(P || p)](https://arxiv.org/abs/2004.03846), [KL(p || q)](https://arxiv.org/abs/2010.05010), [KL(tractable || intractable?)](https://openreview.net/pdf?id=ZrBZrf-BS3Z), [KL (different modality)](https://arxiv.org/abs/2112.06482).


We have some research intern positions available in [Alibaba DAMO Academy](https://damo.alibaba.com/). If you are interested in NLP and ML, please feel free to contact me: jiangyong.ml@gmail.com.

