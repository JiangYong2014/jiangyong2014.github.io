<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yong Jiang</title>
    <link>https://jiangyong.site/authors/admin/</link>
      <atom:link href="https://jiangyong.site/authors/admin/index.xml" rel="self" type="application/rss+xml" />
    <description>Yong Jiang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://jiangyong.site/img/icon-192.png</url>
      <title>Yong Jiang</title>
      <link>https://jiangyong.site/authors/admin/</link>
    </image>
    
    <item>
      <title></title>
      <link>https://jiangyong.site/authors/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://jiangyong.site/authors/admin/</guid>
      <description>&lt;p&gt;Hi! I currently work at &lt;a href=&#34;https://damo.alibaba.com/&#34; target=&#34;_blank&#34;&gt;Alibaba DAMO Academy&lt;/a&gt;. I received my Ph.D from the joint program of ShanghaiTech University and University of Chinese Academy of Sciences. I was very fortunate to be advised by &lt;a href=&#34;http://faculty.sist.shanghaitech.edu.cn/faculty/tukw/&#34; target=&#34;_blank&#34;&gt;Prof. Kewei Tu&lt;/a&gt;. I am interested in machine learning and natural language processing.&lt;/p&gt;

&lt;p&gt;My current research mainly focuses on multilingual NLP, structured prediction and so on. In my PhD time, I mainly worked on learning latent variable models for NLP problems and ML problems.&lt;/p&gt;

&lt;p&gt;Spotlight of our recent work:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Knowledge distillation for learning multilingual models: &lt;a href=&#34;https://arxiv.org/abs/2004.03846&#34; target=&#34;_blank&#34;&gt;structure-level KD&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2010.05010&#34; target=&#34;_blank&#34;&gt;structural KD&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Improving sequence labeling methods: &lt;a href=&#34;https://arxiv.org/abs/2011.05604&#34; target=&#34;_blank&#34;&gt;designing better potential functions&lt;/a&gt;, &lt;a href=&#34;https://openreview.net/pdf?id=ZrBZrf-BS3Z&#34; target=&#34;_blank&#34;&gt;speeding up CRF training &amp;amp; inference&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Leveraging source models to improve cross-lingual ability: &lt;a href=&#34;https://aclanthology.org/2021.acl-long.380/&#34; target=&#34;_blank&#34;&gt;risk minimization&lt;/a&gt;, &lt;a href=&#34;https://aclanthology.org/2021.acl-long.207/&#34; target=&#34;_blank&#34;&gt;multi-view learning&lt;/a&gt;, &lt;a href=&#34;https://jiangyong.site&#34; target=&#34;_blank&#34;&gt;word reordering&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Incorporating various kinds of knowledge to improve NER, sequence labeling and structured prediction: &lt;a href=&#34;https://arxiv.org/abs/2009.08330&#34; target=&#34;_blank&#34;&gt;embedding combination&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2010.05006&#34; target=&#34;_blank&#34;&gt;ACE&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2105.03654&#34; target=&#34;_blank&#34;&gt;retrieval guided learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Unsupervised grammar induction: &lt;a href=&#34;https://arxiv.org/abs/2010.14720&#34; target=&#34;_blank&#34;&gt;2nd order parsing&lt;/a&gt;, &lt;a href=&#34;https://github.com/tukw/unsupervised-parsing-tutorial&#34; target=&#34;_blank&#34;&gt;EACL tutorial&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Improving &lt;a href=&#34;https://arxiv.org/abs/2105.03654&#34; target=&#34;_blank&#34;&gt;NER performance&lt;/a&gt; and &lt;a href=&#34;https://jiangyong.site&#34; target=&#34;_blank&#34;&gt;Entity linking performance&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We have some research intern positions available in &lt;a href=&#34;https://damo.alibaba.com/&#34; target=&#34;_blank&#34;&gt;Alibaba DAMO Academy&lt;/a&gt;. If you are interested in NLP and ML, please feel free to contact me: jiangyong.ml@@gmail.com.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
